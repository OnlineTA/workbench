workbench â€” a testbed for OnlineTA tests

OnlineTA workbench is a light-weight, cross-platform mimic implementation of
the OnlineTA testing interface. It is intended as a programming environment for
teachers to write assignments to be tested online with OnlineTA.

In principle, you can use workbench to test student submissions locally, but
beware that workbench only mirros the OnlineTA testing interface, and DOES NOT
perform any sandboxing. What might be safe to test online, is not likely to be
safe to test with the workbench. That is, unless you trust the students not to
misbehave beyond reason, or fancy living on the edge.

# Example

See the ./assignments/ subdirectory for some sample assignments. For each of
them, there are a couple sample good and bad solutions under
./submissions/<assignment>/.

For instance, you might consider running:

  $ ./workbench ./assignments/c-stackcalc/ ./submissions/c-stackcalc/good/

# Testing Interface

The testing of a submission is stratified into strata, or phases. This has
multiple benefits:

1. Preconditioning. For instance:

  * Student code must be adequately structured (e.g. contain a src directory)
    for any further analysis to take place.

  * Student code must compile before we can try to run it.

  * Student code must finish executing before we do any post-processing of the
    resulting environment.

2  Security. There are several benefits in terms of security:

  a. Breaking out of the sandbox in one strata, does not (immediately) give
     any means to exploit the next strata.

  b. Different sandboxing models can be employed at different strata;
     reinforcing benefit 2.a., requiring to break out of multiple sandboxing
     approaches for ultimate exploitation of the testing system.

One particular application of benefit 2.b., as exemplified in this workbench,
is the split between static and dynamic testing.

# Static Strata

By declaring a static stratum, the teacher states that within this stratum, the
student submission is to be regarded as data --- it should never be succeptible
to execution. Here, the teacher would like access to the files of the
submission, and perhaps modify and create new files to pass on to future
strata. Some examples of static tests include:

  * check if all the necessary files are present;
  * run student code through a linter;
  * compile the student code; and
  * look for relevant regular and context-free patterns in the student code.

Crucially, the source code of the static tests does not reveal the essential
structure of a working solution to the assignment, merely some of its
constituents (e.g. you should have a src directory, your code should compile
without warnings, you should be using higher-order functions, etc.)

If the student breaks out of the sandbox of a static stratum and gets to see
the source code of the static tests, it will only give the insight which was
already readily available through hints, or give insight into how to game the
static tests. The latter problem can be caught due to breakage of subsequent
strata, one of which should be a human TA.

(Outbreaks: The typical statement "breaking out of the sandbox" is more nuanced
when simple andboxing mechanisms are composed to form more intricate sandboxes.
For instance, it might be easier to leak the assessment code of a static strata
than it is to leak other students' submissions, or make OnlineTA terminate the
assessment prematurely with the grade that the student gets to decide.)

# Dynamic Strata

By declaring a dynamic stratum, the teacher states that access is only needed
to e.g. the input and output streams of the program submitted by the student
(and not its source code). This means that the teacher and student code can run
sandboxed from each other, and communicate via sockets, or a further
constrained protocol. Some examples of dynamic tests include:

  * property-test (unit-test, etc.) the student code; and
  * compare the student output with the output from a reference solution.

Critically, the above tests can reveal the intricate details of a working
solution. This means that the execution of student code should be more
aggressively sandboxed from both the source code, and the execution of
assessment code.

# Why separate static and dynamic tests?

Of course, in the presence of vulnerabilities in assessment code, what is
regarded as data may quickly turn into programs; and of course, source code can
be exchanged via sockets.

The separation into static and dynamic strata permits merely to employ
different security models for each type of strata: employ different sandboxing
models for each type, and make clear, differentiating statements about their
intent.  In particular, the static/dynamic split seems fairly self-evident for
teachers in Computer Science to follow.
